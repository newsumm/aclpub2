- abstract: Recently, the emergence of ChatGPT has attracted wide attention from the computational linguistics community. Many prior studies have shown that ChatGPT achieves remarkable performance on various NLP tasks in terms of automatic evaluation metrics. However, the ability of ChatGPT to serve as an evaluation metric is still underexplored. Considering assessing the quality of natural language generation (NLG) models is an arduous task and NLG metrics notoriously show their poor correlation with human judgments, we wonder whether ChatGPT is a good NLG evaluation metric. In this report, we provide a preliminary meta-evaluation on ChatGPT to show its reliability as an NLG metric. In detail, we regard ChatGPT as a human evaluator and give task-specific (e.g., summarization) and aspect-specific (e.g., relevance) instruction to prompt ChatGPT to evaluate the generated results of NLG models. We conduct experiments on five NLG meta-evaluation datasets (including summarization, story generation and data-to-text tasks). Experimental results show that compared with previous automatic metrics, ChatGPT achieves state-of-the-art or competitive correlation with human judgments in most cases. In addition, we find that the effectiveness of the ChatGPT evaluator might be influenced by the creation method of the meta-evaluation datasets. For the meta-evaluation datasets which are created greatly depending on the reference and thus are biased, the ChatGPT evaluator might lose its effectiveness. We hope our preliminary study could prompt the emergence of a general-purposed reliable NLG metric.
  attachments:
  - file: attachments/1_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: ''
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: jawang.nlp@gmail.com
    first_name: Jiaan
    institution: School of Computer Science and Technology, Soochow University, Suzhou, China
    last_name: Wang
    name: Jiaan Wang
    username: krystal4n
  - emails: yunlonliang@gmail.com
    first_name: Yunlong
    institution: Beijing Jiaotong University
    last_name: Liang
    name: Yunlong Liang
    username: yunlongliang
  - emails: fandongmeng@tencent.com
    first_name: Fandong
    institution: WeChat AI, Tencent
    last_name: Meng
    name: Fandong Meng
    username: mengfandong
  - emails: acerkoo747@gmail.com
    first_name: Zengkui
    institution: Beijing Jiaotong university
    last_name: Sun
    name: Zengkui Sun
    username: zengksun
  - emails: hollis.shi@toki.waseda.jp
    first_name: Haoxiang
    institution: Waseda University
    last_name: Shi
    name: Haoxiang Shi
    username: a1007081080
  - emails: zhixuli@fudan.edu.cn
    first_name: Zhixu
    institution: Fudan University
    last_name: Li
    name: Zhixu Li
    username: zhixuli
  - emails: jaxu@bjtu.edu.cn
    first_name: Jinan
    institution: Beijing Jiaotong University
    last_name: Xu
    name: Jinan Xu
    username: jaxu
  - emails: jfqu@suda.edu.cn
    first_name: Jianfeng
    institution: Soochow University
    last_name: Qu
    name: Jianfeng Qu
    username: jianfeng
  - emails: withtomzhou@tencent.com
    first_name: Jie
    institution: Tencent Inc.
    last_name: Zhou
    name: Jie Zhou
    username: jerryitp
  decision: Accept to main conference
  file: 1.pdf
  id: '1'
  title: Is ChatGPT a Good NLG Evaluator? A Preliminary Study
- abstract: Given a document in a source language, cross-lingual summarization (CLS) aims to generate a summary in a different target language. Recently, the emergence of Large Language Models (LLMs), such as GPT-3.5, ChatGPT and GPT-4, has attracted wide attention from the computational linguistics community. However, it is not yet known the performance of LLMs on CLS. In this report, we empirically use various prompts to guide LLMs to perform zero-shot CLS from different paradigms (i.e., end-to-end and pipeline), and provide a preliminary evaluation on the generated summaries. We find that ChatGPT and GPT-4 originally prefer to produce lengthy summaries with detailed information. These two LLMs can further balance informativeness and conciseness with the help of an interactive prompt, significantly improving their CLS performance. Experimental results on three widely-used CLS datasets show that GPT-4 achieves state-of-the-art zero-shot CLS performance, and performs competitively compared with the fine-tuned mBART-50. Moreover, we also find some multi-lingual and bilingual LLMs (i.e., BLOOMZ, ChatGLM-6B, Vicuna-13B and ChatYuan) have limited zero-shot CLS ability. Due to the composite nature of CLS, which requires models to perform summarization and translation simultaneously, accomplishing this task in a zero-shot manner is even a challenge for LLMs. Therefore, we sincerely hope and recommend future LLM research could use CLS as a testbed.
  attachments:
  - file: attachments/2_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: ''
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: jawang.nlp@gmail.com
    first_name: Jiaan
    institution: School of Computer Science and Technology, Soochow University, Suzhou, China
    last_name: Wang
    name: Jiaan Wang
    username: krystal4n
  - emails: yunlonliang@gmail.com
    first_name: Yunlong
    institution: Beijing Jiaotong University
    last_name: Liang
    name: Yunlong Liang
    username: yunlongliang
  - emails: fandongmeng@tencent.com
    first_name: Fandong
    institution: WeChat AI, Tencent
    last_name: Meng
    name: Fandong Meng
    username: mengfandong
  - emails: bqzic99@gmail.com
    first_name: Beiqi
    institution: PrincetonUniversity
    last_name: Zou
    name: Beiqi Zou
    username: beiqizou
  - emails: zhixuli@fudan.edu.cn
    first_name: Zhixu
    institution: Fudan University
    last_name: Li
    name: Zhixu Li
    username: zhixuli
  - emails: jfqu@suda.edu.cn
    first_name: Jianfeng
    institution: Soochow University
    last_name: Qu
    name: Jianfeng Qu
    username: jianfeng
  - emails: withtomzhou@tencent.com
    first_name: Jie
    institution: Tencent Inc.
    last_name: Zhou
    name: Jie Zhou
    username: jerryitp
  decision: Accept to main conference
  file: 2.pdf
  id: '2'
  title: Zero-Shot Cross-Lingual Summarization via Large Language Models
- abstract: Cross-lingual science journalism is a recently introduced task that generates popular science summaries of scientific articles different from the source language for non-expert readers. A popular science summary must contain salient content of the input document while focusing on coherence and comprehensibility. Meanwhile, generating a cross-lingual summary from the scientific texts in a local language for the targeted audience is challenging. Existing research on cross-lingual science journalism investigates the task with a pipeline model to combine text simplification and cross-lingual summarization. We extend the research in cross-lingual science journalism by introducing a novel, multi-task learning architecture that combines the aforementioned NLP tasks. Our approach is to jointly train the two high-level NLP tasks in SimCSum for generating cross-lingual popular science summaries. We investigate the performance of SimCSum against the pipeline model and several other strong baselines with several evaluation metrics and human evaluation. Overall, SimCSum demonstrates statistically significant improvements over the state-of-the-art on two non-synthetic cross-lingual scientific datasets. Furthermore, we conduct an in-depth investigation into the linguistic properties of generated summaries and an error analysis.
  attachments:
  - file: attachments/3_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: mehwishfatima.raja@gmail.com
    first_name: Mehwish
    institution: Heidelberg Institute for Theoretical Studies
    last_name: Fatima
    name: Mehwish Fatima
    username: mehwish_fatima
  - emails: tim.kolber@h-its.org
    first_name: Tim
    institution: Heidelberg Institute for Theoretical Studies
    last_name: Kolber
    name: Tim Kolber
    username: timkolber
  - emails: markert@cl.uni-heidelberg.de
    first_name: Katja
    institution: Heidelberg University
    last_name: Markert
    name: Katja Markert
    username: k.markert
  - emails: michael.strube@h-its.org
    first_name: Michael
    institution: Heidelberg Institute for Theoretical Studies
    last_name: Strube
    name: Michael Strube
    username: strube
  decision: Accept to main conference
  file: 3.pdf
  id: '3'
  title: 'SimCSum: Joint Learning of Simplification and Cross-lingual Summarization for Cross-lingual Science Journalism'
- abstract: "A modular approach has the advantage of being compositional and controllable, comparing to most end-to-end models.\n  In this paper we propose Extract-Select-Rewrite (ESR), a three-phase abstractive sentence summarization method.\n  We decompose summarization into three stages:\n  (i) knowledge extraction, where we extract relation triples from the text using off-the-shelf tools;\n  (ii) content selection, where a subset of triples are selected;\n  and (iii) rewriting, where the selected triple are realized into natural language.\n  Our results demonstrates that ESR is competitive with the best end-to-end models while being more faithful. \\%than these baseline models.\n  Being modular, ESR's modules can be trained on separate data which is beneficial in low-resource settings and enhancing the style controllability on text generation."
  attachments:
  - file: attachments/7_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: shuo.guan@cs.nyu.edu
    first_name: Shuo
    institution: UBS
    last_name: Guan
    name: Shuo Guan
    username: seanguan
  - emails: vp1271@nyu.edu
    first_name: Vishakh
    institution: New York University
    last_name: Padmakumar
    name: Vishakh Padmakumar
    username: vishakhpk
  decision: Accept to main conference
  file: 7.pdf
  id: '7'
  title: 'Extract, Select and Rewrite: A Modular Sentence Summarization Method'
- abstract: Despite the prevalence of pretrained language models in natural language understanding tasks, understanding lengthy text such as document is still challenging due to the data sparseness problem. Inspired by that humans develop their ability of understanding lengthy text form reading shorter text, we propose a simple yet effective summarization-based data augmentation, SUMMaug, for document classification. We first obtain easy-to-learn examples for the target document classification task by summarizing the input of the original training examples, while optionally merging the original labels to conform to the summarized input. We then use the generated pseudo examples to perform curriculum learning. Experimental results on two datasets confirmed the advantage of our method compared to existing baseline methods in terms of robustness and accuracy. We release our code and data at https://github.com/etsurin/summaug.
  attachments:
  - file: attachments/9_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: etsurin@iis.u-tokyo.ac.jp
    first_name: Yueguan
    institution: the University of Tokyo
    last_name: Wang
    name: Yueguan Wang
    username: etsurin
  - emails: ynaga@iis.u-tokyo.ac.jp
    first_name: Naoki
    institution: Institute of Industrial Science, The University of Tokyo
    last_name: Yoshinaga
    name: Naoki Yoshinaga
    username: ynaga
  decision: Accept to main conference
  file: 9.pdf
  id: '9'
  title: Summarization-based Data Augmentation for Document Classification
- abstract: Large Language Models (LLMs) have shown significant performance in numerous NLP tasks, including summarization and controlled text generation. A notable capability of LLMs is in-context learning (ICL), where the model learns new tasks using input-output pairs in the prompt without any parameter update. However, the performance of LLMs in the context of few-shot abstractive dialogue summarization remains underexplored. This study evaluates various state-of-the-art LLMs on the SAMSum dataset within a few-shot framework. We assess these models in both controlled (entity control, length control, and person-focused planning) and uncontrolled settings, establishing a comprehensive benchmark in few-shot dialogue summarization. Our findings provide insights into summary quality and model controllability, offering a crucial reference for future research in dialogue summarization.
  attachments:
  - file: attachments/12_LaTeXSource.zip
    type: Supplementary Material
  - file: attachments/12_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: ytang021@e.ntu.edu.sg
    first_name: Yuting
    institution: Nanyang Technological University
    last_name: Tang
    name: Yuting Tang
    username: yuting_tang
  - emails: puduppully_ratish_surendran@i2r.a-star.edu.sg
    first_name: Ratish
    institution: Institute for Infocomm Research (I2R), A*STAR, Singapore
    last_name: Puduppully
    name: Ratish Puduppully
    username: ''
  - emails: Liu_Zhengyuan@i2r.a-star.edu.sg
    first_name: Zhengyuan
    institution: Institute for Infocomm Research (I2R), A*STAR, Singapore
    last_name: Liu
    name: Zhengyuan Liu
    username: ''
  - emails: nfychen@i2r.a-star.edu.sg
    first_name: Nancy
    institution: Institute for Infocomm Research (I2R), A*STAR, Singapore
    last_name: Chen
    name: Nancy Chen
    username: ''
  decision: Accept to main conference
  file: 12.pdf
  id: '12'
  title: 'In-context Learning of Large Language Models for Controlled Dialogue Summarization: A Holistic Benchmark and Empirical Analysis'
- abstract: Selecting the ``right'' amount of information to include in a summary is a difficult task. A good summary should be detailed and entity-centric without being overly dense and hard to follow. To better understand this tradeoff, we solicit increasingly dense GPT-4 summaries with what we refer to as a ``Chain of Density'' (CoD) prompt. Specifically, GPT-4 generates an initial entity-sparse summary before iteratively incorporating missing salient entities without increasing the length. Summaries generated by CoD are more abstractive, exhibit more fusion, and have less of a lead bias than GPT-4 summaries generated by a vanilla prompt. We conduct a human preference study on 100 CNN DailyMail articles and find that humans prefer GPT-4 summaries that are more dense than those generated by a vanilla prompt and almost as dense as human written summaries. Qualitative analysis supports the notion that there exists a tradeoff between informativeness and readability. 500 annotated CoD summaries, as well as an extra 5,000 unannotated summaries, are freely available on HuggingFace (https://huggingface.co/datasets/griffin/chain\_of\_density).
  attachments:
  - file: attachments/13_LaTeXSource.zip
    type: Supplementary Material
  - file: attachments/13_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: griffin.adams@columbia.edu
    first_name: Griffin
    institution: Columbia University
    last_name: Adams
    name: Griffin Adams
    username: griffinadams
  - emails: afabbri@salesforce.com
    first_name: Alex
    institution: Salesforce AI Research
    last_name: Fabbri
    name: Alex Fabbri
    username: alexfabbri
  - emails: faisal@cs.columbia.edu
    first_name: Faisal
    institution: Columbia University
    last_name: Ladhak
    name: Faisal Ladhak
    username: kvothe
  - emails: lehmer16@mit.edu
    first_name: Eric
    institution: MIT
    last_name: Lehman
    name: Eric Lehman
    username: lehmer16
  - emails: noemie.elhadad@columbia.edu
    first_name: Noémie
    institution: Columbia University
    last_name: Elhadad
    name: Noémie Elhadad
    username: noemie
  decision: Accept to main conference
  file: 13.pdf
  id: '13'
  title: 'From Sparse to Dense: GPT-4 Summarization with Chain of Density Prompting'
- abstract: Summarization of scientific articles often overlooks insights from citing papers, focusing solely on the document's content. To incorporate citation contexts, we develop a model to summarize a scientific document using the information in the source and citing documents. It concurrently generates abstractive and extractive summaries, each enhancing the other. The extractive summarizer utilizes a blend of heterogeneous graph-based neural networks and graph attention networks, while the abstractive summarizer employs an autoregressive decoder. These modules exchange control signals through the loss function, ensuring the creation of high-quality summaries in both styles.
  attachments:
  - file: attachments/14_LaTeXSource.zip
    type: Supplementary Material
  - file: attachments/14_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: ssinghar@uwo.ca
    first_name: Sudipta
    institution: University of Western Ontario
    last_name: Singha Roy
    name: Sudipta Singha Roy
    username: ssinghar
  - emails: mercer@csd.uwo.ca
    first_name: Robert E.
    institution: The University of Western Ontario
    last_name: Mercer
    name: Robert E. Mercer
    username: robertmercer
  decision: Accept to main conference
  file: 14.pdf
  id: '14'
  title: Generating Extractive and Abstractive Summaries in Parallel from Scientific Articles Incorporating Citing Statements
- abstract: The centroid method is a simple approach for extractive multi-document summarization and many improvements to its pipeline have been proposed. We further refine it by adding a beam search process to the sentence selection and also a centroid estimation attention model that leads to improved results. We demonstrate this in several multi-document summarization datasets, including in a multilingual scenario.
  attachments:
  - file: attachments/15_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Regular Paper
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: simao.goncalves@priberam.pt
    first_name: Simão
    institution: Priberam
    last_name: Gonçalves
    name: Simão Gonçalves
    username: ''
  - emails: goncalommac@gmail.com
    first_name: Gonçalo
    institution: Priberam
    last_name: Correia
    name: Gonçalo Correia
    username: goncalomcorreia
  - emails: diogo.pernes@priberam.pt
    first_name: Diogo
    institution: Priberam; University of Porto
    last_name: Pernes
    name: Diogo Pernes
    username: dpernes
  - emails: amm@priberam.pt
    first_name: Afonso
    institution: Priberam Informática, SA.
    last_name: Mendes
    name: Afonso Mendes
    username: afonsoamendes
  decision: Accept to main conference
  file: 15.pdf
  id: '15'
  title: Supervising the Centroid Baseline for Extractive Multi-Document Summarization
- abstract: 'Recent work within the Argument Mining community has shown the applicability of Natural Language Processing systems for solving problems found within competitive debate. One of the most important tasks within competitive debate is for debaters to create high quality debate cases. We show that effective debate cases can be constructed using constrained shortest path traversals on Argumentative Semantic Knowledge Graphs. We study this potential in the context of a type of American Competitive Debate, called "Policy Debate", which already has a large scale dataset targeting it called "DebateSum". We significantly improve upon DebateSum by introducing 53180 new examples, as well as further useful metadata for every example, to the dataset. We leverage the txtai semantic search and knowledge graph toolchain to produce and contribute 9 semantic knowledge graphs built on this dataset. We create a unique method for evaluating which knowledge graphs are better in the context of producing policy debate cases. A demo which automatically generates debate cases, along with all other code and the Knowledge Graphs, are open-sourced and made available to the public here: https://huggingface.co/spaces/Hellisotherpeople/DebateKG'
  attachments:
  - file: attachments/25_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Fast-track
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: gedboy2112@gmail.com
    first_name: Allen
    institution: University of Oregon
    last_name: Roush
    name: Allen Roush
    username: der_einzige
  - emails: david.mezzetti@neuml.com
    first_name: David
    institution: NeuML
    last_name: Mezzetti
    name: David Mezzetti
    username: ''
  decision: Accept to main conference
  file: 25.pdf
  id: '25'
  title: DebateKG – Automatic Policy Debate Case Creation with Semantic Knowledge Graphs
- abstract: 'Opinion summarization is the task of creating summaries capturing popular opinions from user reviews.

    In this paper, we introduce Geodesic Summarizer (GeoSumm), a novel system to perform unsupervised extractive opinion summarization.  GeoSumm consists of an encoder-decoder based representation learning model that generates topical representations of texts. These representations capture the underlying semantics of the text as a distribution over learnable latent units. GeoSumm generates these topical representations by performing dictionary learning over pre-trained text representations at multiple layers of the decoder. We then use these topical representations to quantify the importance of review sentences using a novel approximate geodesic distance-based scoring mechanism. We use the importance scores to identify popular opinions in order to compose general and aspect-specific summaries. Our proposed model, GeoSumm, achieves strong performance on three opinion summarization datasets. We perform additional experiments to analyze the functioning of our model and showcase the generalization ability of GeoSumm across different domains.'
  attachments:
  - file: attachments/29_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Fast-track
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: somnath@cs.unc.edu
    first_name: Somnath
    institution: University of North Carolina at Chapel Hill
    last_name: Basu Roy Chowdhury
    name: Somnath Basu Roy Chowdhury
    username: somnathbrc
  - emails: nmonath@google.com
    first_name: Nicholas
    institution: Google
    last_name: Monath
    name: Nicholas Monath
    username: nmonath
  - emails: avinava.dubey@gmail.com
    first_name: Kumar
    institution: Google Research
    last_name: Dubey
    name: Kumar Dubey
    username: avinava
  - emails: amra@google.com
    first_name: Amr
    institution: Research Scientist, Google Research
    last_name: Ahmed
    name: Amr Ahmed
    username: amrahmed
  - emails: snigdhac@gmail.com
    first_name: Snigdha
    institution: University of North Carolina, Chapel Hill
    last_name: Chaturvedi
    name: Snigdha Chaturvedi
    username: snigdha
  decision: Accept to main conference
  file: 29.pdf
  id: '29'
  title: Unsupervised Opinion Summarization Using Approximate Geodesics
- abstract: Abstractive summarization systems aim to write concise summaries capturing the most essential information of the input document in their own words. One of the ways to achieve this is to gather and combine multiple pieces of information from the source document, a process we call aggregation. Despite its importance, the extent to which both reference summaries in benchmark datasets and system-generated summaries require aggregation is yet unknown. In this work, we propose AggSHAP, a measure of the degree of aggregation in a summary sentence. We show that AggSHAP distinguishes multi-sentence aggregation from single-sentence extraction or paraphrasing through automatic and human evaluations. We find that few reference or model-generated summary sentences have a high degree of aggregation measured by the proposed metric. We also demonstrate negative correlations between AggSHAP and other quality scores of system summaries. These findings suggest the need to develop new tasks and datasets to encourage multi-sentence aggregation in summarization.
  attachments:
  - file: attachments/30_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Fast-track
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: jingyi.he@mail.mcgill.ca
    first_name: Jingyi
    institution: McGill University
    last_name: He
    name: Jingyi He
    username: kyliehe616
  - emails: meng.cao@mail.mcgill.ca
    first_name: Meng
    institution: McGill University
    last_name: Cao
    name: Meng Cao
    username: caden
  - emails: jcheung@cs.mcgill.ca
    first_name: Jackie Chi Kit
    institution: Mila / McGill University
    last_name: Cheung
    name: Jackie Chi Kit Cheung
    username: jcheung
  decision: Accept to main conference
  file: 30.pdf
  id: '30'
  title: Analyzing Multi-Sentence Aggregation in Abstractive Summarization via the Shapley Value
- abstract: Multi-stage long document summarization, which splits a long document as multiple segments and each of which is used to generate a coarse summary in multiple stage, and then the final summary is produced using the last coarse summary, is a flexible approach to capture salient information from the long document. Even if the coarse summary affects the final summary, however, the coarse summarizer in the existing multi-stage summarization is coarsely trained using data segments that are not useful to generate the final summary. In this paper, we propose a novel method for multi-stage long document summarization. The proposed method first generates new segment pairs, ensuring that all of them are relevant to generating the final summary. We then incorporate contrastive learning into the training of the coarse summarizer, which tries to maximize the similarities between source segments and the target summary during training. Through extensive experiments on six long document summarization datasets, we demonstrate that our proposed method not only enhances the existing multi-stage long document summarization approach, but also achieves performance comparable to state-of-the-art methods, including those utilizing large language models for long document summarization.
  attachments:
  - file: attachments/31_LaTeXSource.zip
    type: Supplementary Material
  - file: attachments/31_metadata.txt
    type: Supplementary Material
  attributes:
    paper_type: Fast-track
    presentation_type: N/A
    submitted_area: ''
  authors:
  - emails: dlawlsgudsu@naver.com
    first_name: Jinhyeong
    institution: Graduate School of Electrical Engineering and Computer Science, Jeonbuk National University
    last_name: Lim
    name: Jinhyeong Lim
    username: jinhyeong-lim
  - emails: songhyunje@gmail.com
    first_name: Hyun-Je
    institution: Jeonbuk National University
    last_name: Song
    name: Hyun-Je Song
    username: hyunjeng
  decision: Accept to main conference
  file: 31.pdf
  id: '31'
  title: Improving Multi-Stage Long Document Summarization with Enhanced Coarse Summarizer
